{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817d8c5e",
   "metadata": {},
   "source": "# Chp 3 Introduction to ML\n\nDecision tree construction relies on recursion, where a function calls itself on smaller versions of the problem until reaching a stopping condition. For example, the factorial function can be defined recursively:\n\n```python\nùëõ! = ùëõ √ó (ùëõ‚àí1)!\n```\n\nIn the same way, decision trees build subtrees by applying the same process recursively on subsets of the training data, until reaching a leaf node.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27e415",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# Factorial\n"
  },
  {
   "cell_type": "markdown",
   "id": "2602f069",
   "metadata": {},
   "source": "# Chp 4 Experiments with Classical Models"
  },
  {
   "cell_type": "markdown",
   "id": "e6703acb",
   "metadata": {},
   "source": "## Iris\n\nThe iris dataset contains four continuous features‚Äîsepal length, sepal width, petal length, and petal width‚Äîand three classes corresponding to iris species. It has 150 samples, 50 per class. Using PCA augmentation, we expand the dataset to 1,200 training samples while keeping the same test set."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T15:13:56.735679Z",
     "start_time": "2025-09-28T15:13:56.733505Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "975260ae2e708e49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-09-28T15:37:39.360811Z",
     "start_time": "2025-09-28T15:37:39.238536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iris Experiments\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load data\n",
    "def load_iris_data():\n",
    "    \"\"\"Load and prepare the iris dataset\"\"\"\n",
    "    iris = load_iris()\n",
    "    X = iris['data']\n",
    "    Y = iris['target']\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "\n",
    "def create_augmented_data(X_train, Y_train):\n",
    "    \"\"\"Create augmented data by adding noise and scaling\"\"\"\n",
    "    return X_train, Y_train\n",
    "\n",
    "\n",
    "def run(X_train, Y_train, X_test, Y_test, clf):\n",
    "    norm = MinMaxScaler().fit(X_train)\n",
    "    X_train_norm = norm.transform(X_train)\n",
    "    X_test_norm = norm.transform(X_test)\n",
    "    \n",
    "    clf.fit(X_train_norm, Y_train)\n",
    "    Y_pred = clf.predict(X_test_norm)\n",
    "    f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "    # print(f\"{f1=}\")\n",
    "    return repr(clf), f1.item()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load iris data\n",
    "    X, Y = load_iris_data()\n",
    "\n",
    "    # Split data (120 for training, rest for testing)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=len(X) - 120, stratify=Y)\n",
    "    # Create augmented data\n",
    "\n",
    "    X_train_aug, Y_train_aug = create_augmented_data(X_train, Y_train)\n",
    "\n",
    "    print(f\"{len(X_train)=}, {len(Y_train)=}, {len(X_test)=}, {len(Y_test)=}\")\n",
    "\n",
    "\n",
    "\n",
    "    # print(\"Nearest centroid:\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, NearestCentroid())\n",
    "    # print(\"k-NN classifier (k=3):\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "    # print(\"Naive Bayes classifier (Gaussian):\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, GaussianNB())\n",
    "    # print(\"Naive Bayes classifier (Multinomial):\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, MultinomialNB())\n",
    "    # print(\"Decision tree classifier:\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, DecisionTreeClassifier())\n",
    "    # print(\"Random forest classifier (estimators=5):\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, RandomForestClassifier(n_estimators=5))\n",
    "\n",
    "    # print(\"SVM (linear, C=1.0):\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, SVC(kernel=\"linear\", C=1.0))\n",
    "    # print(\"SVM (RBF, C=1.0, gamma=0.25):\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.25))\n",
    "    # print(\"SVM (RBF, C=1.0, gamma=0.001, augmented)\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.001))\n",
    "    # print(\"SVM (RBF, C=1.0, gamma=0.001, original)\")\n",
    "    yield run(X_train_aug, Y_train_aug, X_test, Y_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.001))\n",
    "\n",
    "results = list(main())\n",
    "cmap = plt.get_cmap('winter')\n",
    "plt.barh([x for x, _ in results], [x for _, x in results], color=[cmap(x) for _, x in results])\n"
   ],
   "id": "59ed66c73209b4b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_train)=120, len(Y_train)=120, len(X_test)=30, len(Y_test)=30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "id": "8c231fbb",
   "metadata": {},
   "source": [
    "### Implementing a Nearest-Centroid Classifier\n",
    "\n",
    "Even without sklearn, we can quickly implement a nearest-centroid classifier for the iris dataset. The process involves calculating the per-feature means (centroids) of each class from the training samples. This is all that is needed to \"train\" the model. Predictions are made by computing the Euclidean distance from each test sample to the three centroids, assigning the sample to the class with the nearest centroid."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T15:54:36.329572Z",
     "start_time": "2025-09-28T15:54:36.324666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = np.array([[1, 2],[2, 5],[1, 2],[1, 2],[2, 5]])\n",
    "mask = (a[:, 0, np.newaxis] == np.unique(a[:, 0])[np.newaxis, :])\n",
    "(a[:, 1, np.newaxis] * mask).sum(axis=0) / mask.sum(axis=0)"
   ],
   "id": "17255feece8c5d94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 5.])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "id": "3c1b7910",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-09-28T15:55:34.613026Z",
     "start_time": "2025-09-28T15:55:34.535968Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def load_iris_data():\n",
    "    \"\"\"Load and prepare the iris dataset\"\"\"\n",
    "    iris = load_iris()\n",
    "    x = iris.data\n",
    "    y = iris.target\n",
    "    \n",
    "    # Shuffle the data to match typical train/test splits\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    indices = np.random.permutation(len(x))\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def centroids(x,y):\n",
    "    print(x.shape, y.shape)\n",
    "    a = np.stack(x, y)\n",
    "    mask = (a[:, 0, np.newaxis] == np.unique(a[:, 0])[np.newaxis, :])\n",
    "    (a[:, 1, np.newaxis] * mask).sum(axis=0) / mask.sum(axis=0)\n",
    "\n",
    "def predict(c0,c1,c2,x):\n",
    "    ...\n",
    "\n",
    "def main():\n",
    "    # Load iris data using sklearn\n",
    "    x, y = load_iris_data()\n",
    "    \n",
    "    # Split data (120 for training, rest for testing)\n",
    "    N = 120\n",
    "    x_train = x[:N]\n",
    "    x_test = x[N:]\n",
    "    y_train = y[:N]\n",
    "    y_test = y[N:]\n",
    "    \n",
    "    # Calculate centroids and make predictions\n",
    "    c0, c1, c2 = centroids(x_train, y_train)\n",
    "    p = predict(c0,c1,c2, x_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    nc = len(np.where(p == y_test)[0])\n",
    "    nw = len(np.where(p != y_test)[0])\n",
    "    acc = float(nc) / (float(nc)+float(nw))\n",
    "    \n",
    "    print(\"predicted:\", p)\n",
    "    print(\"actual   :\", y_test)\n",
    "    print(\"test accuracy = %0.4f\" % acc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[173]\u001B[39m\u001B[32m, line 52\u001B[39m\n\u001B[32m     49\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mtest accuracy = \u001B[39m\u001B[38;5;132;01m%0.4f\u001B[39;00m\u001B[33m\"\u001B[39m % acc)\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[173]\u001B[39m\u001B[32m, line 39\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     36\u001B[39m y_test = y[N:]\n\u001B[32m     38\u001B[39m \u001B[38;5;66;03m# Calculate centroids and make predictions\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m c0, c1, c2 = \u001B[43mcentroids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     40\u001B[39m p = predict(c0,c1,c2, x_test)\n\u001B[32m     42\u001B[39m \u001B[38;5;66;03m# Calculate accuracy\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[173]\u001B[39m\u001B[32m, line 20\u001B[39m, in \u001B[36mcentroids\u001B[39m\u001B[34m(x, y)\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcentroids\u001B[39m(x,y):\n\u001B[32m     19\u001B[39m     \u001B[38;5;28mprint\u001B[39m(x.shape, y.shape)\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m     a = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     21\u001B[39m     mask = (a[:, \u001B[32m0\u001B[39m, np.newaxis] == np.unique(a[:, \u001B[32m0\u001B[39m])[np.newaxis, :])\n\u001B[32m     22\u001B[39m     (a[:, \u001B[32m1\u001B[39m, np.newaxis] * mask).sum(axis=\u001B[32m0\u001B[39m) / mask.sum(axis=\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/GitHub/JBNU/ML/4-classic-ml-MightyHelper/.venv/lib/python3.13/site-packages/numpy/_core/shape_base.py:463\u001B[39m, in \u001B[36mstack\u001B[39m\u001B[34m(arrays, axis, out, dtype, casting)\u001B[39m\n\u001B[32m    460\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mall input arrays must have the same shape\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    462\u001B[39m result_ndim = arrays[\u001B[32m0\u001B[39m].ndim + \u001B[32m1\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m463\u001B[39m axis = \u001B[43mnormalize_axis_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresult_ndim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    465\u001B[39m sl = (\u001B[38;5;28mslice\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m),) * axis + (_nx.newaxis,)\n\u001B[32m    466\u001B[39m expanded_arrays = [arr[sl] \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m arrays]\n",
      "\u001B[31mTypeError\u001B[39m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "cell_type": "markdown",
   "id": "2059011e",
   "metadata": {},
   "source": "## Breast Cancer\n\nThe breast cancer dataset contains 569 samples, each with 30 continuous features, including 212 malignant and 357 benign cases. Before training, we normalize the dataset by subtracting the mean and dividing by the standard deviation for each feature. Normalization ensures all features are on a similar scale, improving performance for many models.\n\nUsing an 80/20 train-test split (455 training samples and 114 test samples), we train nine classifiers: nearest centroid, k-NN, naive Bayes, decision tree, random forest (two variants), linear SVM, and RBF SVM. For the SVMs, we set the margin constant C to the default 1.0, and Œ≥ for the RBF kernel to 0.0333 (1/30).\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6bda4",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# BC experiments\nimport numpy as np\nfrom sklearn.neighbors import NearestCentroid, KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import StandardScaler\n\ndef load_breast_cancer_data():\n    \"\"\"Load and prepare the breast cancer dataset with standardization\"\"\"\n\n\ndef run(x_train, y_train, x_test, y_test, clf):\n\n\ndef main():\n    # Load breast cancer data with standardization\n    x, y = load_breast_cancer_data()\n    \n    # Split data (455 for training, rest for testing)\n    N = 455 \n    x_train = x[:N]\n    x_test = x[N:]\n    y_train = y[:N]\n    y_test = y[N:]\n    \n    print(f\"Dataset info: {len(x)} samples, {x.shape[1]} features\")\n    print(f\"Training set: {len(x_train)} samples\")\n    print(f\"Test set: {len(x_test)} samples\")\n    print(f\"Class distribution - Training: {np.bincount(y_train)}, Test: {np.bincount(y_test)}\")\n    print()\n\n    print(\"Nearest centroid:\")\n    run(x_train, y_train, x_test, y_test, NearestCentroid())\n    print(\"k-NN classifier (k=3):\")\n    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n    print(\"k-NN classifier (k=7):\")\n    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n    print(\"Naive Bayes classifier (Gaussian):\")\n    run(x_train, y_train, x_test, y_test, GaussianNB())\n    print(\"Decision tree classifier:\")\n    run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n    print(\"Random forest classifier (estimators=5):\")\n    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n    print(\"Random forest classifier (estimators=50):\")\n    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n    print(\"SVM (linear, C=1.0):\")\n    run(x_train, y_train, x_test, y_test, SVC(kernel=\"linear\", C=1.0))\n    print(\"SVM (RBF, C=1.0, gamma=0.03333):\")\n    run(x_train, y_train, x_test, y_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.03333))\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
   "cell_type": "markdown",
   "id": "f86ee989",
   "metadata": {},
   "source": "### Adding k-Fold Validation\n\nTo implement k-fold validation, we first select a value for k. For the breast cancer dataset with 569 samples, a balance is needed: smaller k ensures each fold has enough samples to represent the data reasonably, while larger k helps average out the effects of a ‚Äúbad‚Äù split. A common choice is k = 5, giving roughly 113 samples per fold, with 80% for training and 20% for testing. The code is designed to allow easy adjustment of k."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e312fd",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# BC K-Fold\nimport numpy as np\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import StandardScaler\nimport sys\n\ndef load_breast_cancer_data():\n    \"\"\"Load and prepare the breast cancer dataset with standardization\"\"\"\n    # Load the breast cancer dataset\n    cancer = load_breast_cancer()\n    x = cancer.data\n    y = cancer.target\n    \n    # Normalize the features (subtract mean and divide by std)\n    scaler = StandardScaler()\n    x_standardized = scaler.fit_transform(x)\n    \n    return x_standardized, y\n\ndef run(x_train, y_train, x_test, y_test, clf):\n\n\ndef split(x,y,k,m):\n    ns = int(y.shape[0]/m)\n    s = []\n    for i in range(m):\n    \ts.append([x[(ns*i):(ns*i+ns)],\n                  y[(ns*i):(ns*i+ns)]])\n    x_test, y_test = s[k]\n    x_train = []\n    y_train = []\n    for i in range(m):\n        if (i==k):\n            continue\n        else:\n            a,b = s[i]\n            x_train.append(a)\n            y_train.append(b)\n    x_train = np.array(x_train).reshape(((m-1)*ns,30))\n    y_train = np.array(y_train).reshape((m-1)*ns)\n    return [x_train, y_train, x_test, y_test]\n\ndef pp(z,k,s):\n    m = z.shape[1]\n    print(\"%-19s: %0.4f +/- %0.4f | \" % (s, z[k].mean(), z[k].std()/np.sqrt(m)), end='')\n    for i in range(m):\n        print(\"%0.4f \" % z[k,i], end='')\n    print()\n\ndef main():\n    # Check if k-folds argument is provided\n    if len(sys.argv) != 2:\n        print(\"Usage: python script.py <number_of_folds>\")\n        print(\"Example: python script.py 5\")\n        return\n    \n    # Load breast cancer data with standardization\n    x, y = load_breast_cancer_data()\n    \n    # Shuffle the data\n    np.random.seed(42)  # For reproducibility\n    idx = np.argsort(np.random.random(y.shape[0]))\n    x = x[idx]\n    y = y[idx]\n    \n    m = int(sys.argv[1])\n    print(f\"Performing {m}-fold cross-validation on breast cancer dataset\")\n    print(f\"Dataset: {x.shape[0]} samples, {x.shape[1]} features\")\n    print()\n    \n    z = np.zeros((8,m))\n\n    for k in range(m):\n        x_train, y_train, x_test, y_test = split(x,y,k,m)\n        z[0,k] = run(x_train, y_train, x_test, y_test, NearestCentroid())\n        z[1,k] = run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n        z[2,k] = run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n        z[3,k] = run(x_train, y_train, x_test, y_test, GaussianNB())\n        z[4,k] = run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n        z[5,k] = run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n        z[6,k] = run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n        z[7,k] = run(x_train, y_train, x_test, y_test, SVC(kernel=\"linear\", C=1.0))\n\n    print(\"Results (mean +/- std_error | individual fold scores):\")\n    print(\"-\" * 60)\n    pp(z,0,\"Nearest\"); pp(z,1,\"3-NN\")\n    pp(z,2,\"7-NN\");    pp(z,3,\"Naive Bayes\")\n    pp(z,4,\"Decision tree\");    pp(z,5,\"Random forest (5)\")\n    pp(z,6,\"Random forest (50)\");    pp(z,7,\"SVM (linear)\")\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
   "cell_type": "markdown",
   "id": "ff0f8156",
   "metadata": {},
   "source": "### Fine-Tuning the RBF Kernel SVM\n\nFor the RBF (Gaussian) kernel SVM, both C and Œ≥ must be optimized. A 2D grid search is performed:\n\n- C uses the same range as the linear SVM.\n- Œ≥ is selected from powers of two times the default 1/30, for p ‚àà [‚Äì4, 3].\n\nFor each pair (C, Œ≥), five-fold validation is performed, and the pair with the highest mean accuracy is selected. Repeated runs produce slightly different results due to randomization in the dataset ordering.\n\nOne promising combination is (C, Œ≥) = (10, 0.00417), which achieves a grand mean accuracy of 97.70%, the highest among all models tested on the breast cancer dataset.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df69f6",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# BC RBF SVM Search\nimport numpy as np\nfrom sklearn.svm import SVC \nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import StandardScaler\n\ndef load_breast_cancer_data():\n    \"\"\"Load and prepare the breast cancer dataset with standardization\"\"\"\n    # Load the breast cancer dataset\n    cancer = load_breast_cancer()\n    x = cancer.data\n    y = cancer.target\n    \n    # Normalize the features (subtract mean and divide by std)\n    scaler = StandardScaler()\n    x_standardized = scaler.fit_transform(x)\n    \n    return x_standardized, y\n\ndef run(x_train, y_train, x_test, y_test, clf):\n    clf.fit(x_train, y_train)\n    return clf.score(x_test, y_test)\n\ndef split(x,y,k,m):\n    ns = int(y.shape[0]/m)\n    s = []\n    for i in range(m):\n        s.append([x[(ns*i):(ns*i+ns)], y[(ns*i):(ns*i+ns)]])\n    x_test, y_test = s[k]\n    x_train = []\n    y_train = []\n    for i in range(m):\n        if (i==k):\n            continue\n        else:\n            a,b = s[i]\n            x_train.append(a)\n            y_train.append(b)\n    x_train = np.array(x_train).reshape(((m-1)*ns,30))\n    y_train = np.array(y_train).reshape((m-1)*ns)\n    return [x_train, y_train, x_test, y_test]\n\ndef main():\n    m = 5 \n    \n    # Load breast cancer data with standardization\n    x, y = load_breast_cancer_data()\n    \n    # Shuffle the data\n    np.random.seed(42)  # For reproducibility\n    idx = np.argsort(np.random.random(y.shape[0]))\n    x = x[idx]\n    y = y[idx]\n    \n    print(f\"RBF SVM Hyperparameter Search using {m}-fold cross-validation\")\n    print(f\"Dataset: {x.shape[0]} samples, {x.shape[1]} features\")\n    print()\n\n    Cs = np.array([0.01,0.1,1.0,2.0,10.0,50.0,100.0])\n    gs = (1./30)*2.0**np.array([-4,-3,-2,-1,0,1,2,3])\n    \n    print(\"C values:\", Cs)\n    print(\"Gamma values:\", gs)\n    print()\n    print(\"Searching hyperparameters...\")\n    \n    zmax = 0.0 \n    best_scores = []\n    \n    for i, C in enumerate(Cs): \n        for j, g in enumerate(gs): \n            z = np.zeros(m)\n            for k in range(m):\n                x_train, y_train, x_test, y_test = split(x,y,k,m)\n                z[k] = run(x_train, y_train, x_test, y_test, SVC(C=C,gamma=g,kernel=\"rbf\"))\n            \n            mean_score = z.mean()\n            if (mean_score > zmax):\n                zmax = mean_score\n                bestC = C \n                bestg = g \n                best_scores = z.copy()\n            \n            # Print progress (optional - comment out if too verbose)\n            print(f\"C={C:6.2f}, gamma={g:8.5f}: {mean_score:.4f} (+/- {z.std():.4f})\")\n    \n    print()\n    print(\"=\" * 50)\n    print(\"BEST HYPERPARAMETERS:\")\n    print(\"best C     = %0.5f\" % bestC)\n    print(\"     gamma = %0.5f\" % bestg)\n    print(\"   accuracy= %0.5f (+/- %0.5f)\" % (zmax, best_scores.std()))\n    print(\"individual fold scores:\", [f\"{score:.4f}\" for score in best_scores])\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
   "cell_type": "markdown",
   "id": "ed553cb4",
   "metadata": {},
   "source": "## MNIST\n\nThe final dataset examined in this chapter is the vector version of MNIST, which contains 28√ó28 grayscale images of handwritten digits (0‚Äì9), one per image. MNIST is a foundational dataset in machine learning and deep learning and will be used throughout the book.\n\nMNIST has 60,000 training images and 10,000 test images, roughly balanced across the 10 digits. Because the dataset is large, classical models are trained directly on the training set and tested on the test set, without using k-fold validation.\n\nThe images are converted into vectors of 784 elements (28 √ó 28 pixels), with values from 0 to 255. Three versions of the dataset are considered:\n\n1. Raw byte values (0‚Äì255)\n2. Scaled data to [0, 1) by dividing by 256\n3. Normalized data, where each pixel has its mean subtracted and is divided by its standard deviation\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df99a0c",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# MNIST experiments\nimport time\nimport numpy as np\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn import decomposition\nfrom sklearn.datasets import fetch_openml\n\ndef load_mnist_data(fashion=False):\n    \"\"\"Load MNIST digits or Fashion-MNIST dataset\"\"\"\n\n    \n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Training samples: {len(x_train)}, Test samples: {len(x_test)}\")\n    print(f\"Features: {x_train.shape[1]} (28x28 images)\")\n    print(f\"Classes: {len(np.unique(y))}\")\n    if fashion:\n        class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n                      'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n        print(f\"Class names: {class_names}\")\n    else:\n        print(\"Classes: 0-9 (digits)\")\n    print()\n    \n    return x_train, y_train, x_test, y_test\n\ndef run(x_train, y_train, x_test, y_test, clf):\n\n\ndef train(x_train, y_train, x_test, y_test):\n    print(\"    Nearest centroid          : \", end='')\n    run(x_train, y_train, x_test, y_test, NearestCentroid())\n    print(\"    k-NN classifier (k=3)     : \", end='')\n    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n    print(\"    k-NN classifier (k=7)     : \", end='')\n    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n    print(\"    Naive Bayes (Gaussian)    : \", end='')\n    run(x_train, y_train, x_test, y_test, GaussianNB())\n    print(\"    Decision tree             : \", end='')\n    run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n    print(\"    Random forest (trees=  5) : \", end='')\n    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n    print(\"    Random forest (trees= 50) : \", end='')\n    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n    print(\"    Random forest (trees=500) : \", end='')\n    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=500))\n    print(\"    Random forest (trees=1000): \", end='')\n    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=1000))\n    print(\"    LinearSVM (C=0.01)        : \", end='')\n    run(x_train, y_train, x_test, y_test, LinearSVC(C=0.01, max_iter=2000))\n    print(\"    LinearSVM (C=0.1)         : \", end='')\n    run(x_train, y_train, x_test, y_test, LinearSVC(C=0.1, max_iter=2000))\n    print(\"    LinearSVM (C=1.0)         : \", end='')\n    run(x_train, y_train, x_test, y_test, LinearSVC(C=1.0, max_iter=2000))\n    print(\"    LinearSVM (C=10.0)        : \", end='')\n    run(x_train, y_train, x_test, y_test, LinearSVC(C=10.0, max_iter=2000))\n\ndef main():\n    # SWITCH BETWEEN DATASETS: Uncomment one of the following lines\n    x_train, y_train, x_test, y_test = load_mnist_data(fashion=False)  # MNIST digits\n    # x_train, y_train, x_test, y_test = load_mnist_data(fashion=True)   # Fashion-MNIST\n    \n    print(\"Running classifier experiments...\")\n    print(\"=\" * 70)\n    train(x_train, y_train, x_test, y_test)\n    \n    print(\"\\nRunning experiments with PCA (50 components)...\")\n    print(\"=\" * 70)\n    \n    # Apply PCA for dimensionality reduction\n    pca = decomposition.PCA(n_components=50)\n    x_train_pca = pca.fit_transform(x_train)\n    x_test_pca = pca.transform(x_test)\n    \n    print(f\"Original features: {x_train.shape[1]}, PCA features: {x_train_pca.shape[1]}\")\n    print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.4f}\")\n    print()\n    \n    train(x_train_pca, y_train, x_test_pca, y_test)\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
   "cell_type": "markdown",
   "id": "a6b91178",
   "metadata": {},
   "source": "The code uses LinearSVC instead of SVC for runtime efficiency and multiclass handling. Helper functions track both model accuracy and training/testing time, important due to the dataset‚Äôs larger size. Training is repeated for the raw, scaled, and normalized versions of the dataset.\n\nNormalization uses the training set‚Äôs mean and standard deviation, which are also applied to test data, as these better represent the true distribution. PCA is also applied, reducing the 784 features to 15 principal components, capturing just over 33% of the variance.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2eddb",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "def main():\n    # SWITCH BETWEEN DATASETS: Uncomment one of the following lines\n    x_train, y_train, x_test, y_test = load_mnist_data(fashion=False)  # MNIST digits\n    # x_train, y_train, x_test, y_test = load_mnist_data(fashion=True)   # Fashion-MNIST\n    \n    # Convert back to [0,255] range to match original preprocessing steps\n    x_train = (x_train * 255.0).astype(\"float64\")\n    x_test = (x_test * 255.0).astype(\"float64\")\n\n    print(\"Models trained on raw [0,255] images:\")\n    train(x_train, y_train, x_test, y_test)\n    print(\"Models trained on raw [0,1) images:\")\n    train(x_train/256.0, y_train, x_test/256.0, y_test)\n\n    m = x_train.mean(axis=0)\n    s = x_train.std(axis=0) + 1e-8\n    x_ntrain = (x_train - m) / s\n    x_ntest  = (x_test - m) / s\n\n    print(\"Models trained on normalized images:\")\n    train(x_ntrain, y_train, x_ntest, y_test)\n\n    pca = decomposition.PCA(n_components=15)\n    pca.fit(x_ntrain)\n    x_ptrain = pca.transform(x_ntrain)\n    x_ptest = pca.transform(x_ntest)\n    \n    print(\"Models trained on first 15 PCA components of normalized images:\")\n    train(x_ptrain, y_train, x_ptest, y_test)\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
   "cell_type": "markdown",
   "id": "d69bd101",
   "metadata": {},
   "source": "### Experimenting with PCA Components\n\nPreviously, 15 PCA components were used, representing about 33% of the dataset‚Äôs variance. To explore the effect of PCA further, the number of components is varied from 10 to 780, and three models are trained for each setting: Gaussian naive Bayes, random forest (50 trees), and linear SVM (C = 1.0). This process is computationally intensive and took over 10 hours on a low-end machine.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506c2bd",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# PCA Component Experiments\nimport time\nimport numpy as np\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn import decomposition\nfrom sklearn.datasets import fetch_openml\n\ndef load_mnist_data(fashion=False):\n    \"\"\"Load MNIST digits or Fashion-MNIST dataset\"\"\"\n    if fashion:\n        # Load Fashion-MNIST dataset\n        print(\"Loading Fashion-MNIST dataset...\")\n        X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False)\n        dataset_name = \"Fashion-MNIST\"\n    else:\n        # Load MNIST digits dataset  \n        print(\"Loading MNIST digits dataset...\")\n        X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n        dataset_name = \"MNIST digits\"\n    \n    # Convert to proper data types\n    X = X.astype(np.float64)\n    y = y.astype(np.int32)\n    \n    # Use standard train/test split (first 60000 for train, last 10000 for test)\n    x_train = X[:60000]\n    x_test = X[60000:]\n    y_train = y[:60000] \n    y_test = y[60000:]\n    \n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Training samples: {len(x_train)}, Test samples: {len(x_test)}\")\n    print(f\"Features: {x_train.shape[1]} (28x28 images)\")\n    print()\n    \n    return x_train, y_train, x_test, y_test\n\ndef run(x_train, y_train, x_test, y_test, clf):\n    s = time.time()\n    clf.fit(x_train, y_train)\n    e_train = time.time() - s \n    s = time.time()\n    score = clf.score(x_test, y_test)\n    e_test = time.time() - s \n    return [score, e_train, e_test]\n\ndef main():\n    # SWITCH BETWEEN DATASETS: Uncomment one of the following lines\n    x_train, y_train, x_test, y_test = load_mnist_data(fashion=False)  # MNIST digits\n    # x_train, y_train, x_test, y_test = load_mnist_data(fashion=True)   # Fashion-MNIST\n    \n    # Normalize the data (z-score normalization)\n    m = x_train.mean(axis=0)\n    s = x_train.std(axis=0) + 1e-8\n    x_ntrain = (x_train - m) / s \n    x_ntest = (x_test - m) / s \n    \n    print(\"Running PCA component analysis...\")\n    print(\"Testing components from 10 to 780 (78 different values)\")\n    print()\n\n    n = 78\n    pcomp = np.linspace(10, 780, n, dtype=\"int16\")\n    nb = np.zeros((n, 4))  # [n_components, score, train_time, test_time]\n    rf = np.zeros((n, 4))\n    sv = np.zeros((n, 4))\n    tv = np.zeros((n, 2))  # [n_components, explained_variance_ratio]\n\n    print(\"Progress:\")\n    for i, p in enumerate(pcomp):\n        print(f\"Testing {p} components... ({i+1}/{n})\", end=\" \")\n        \n        pca = decomposition.PCA(n_components=p)\n        pca.fit(x_ntrain)\n        xtrain = pca.transform(x_ntrain)\n        xtest = pca.transform(x_ntest)\n        tv[i, :] = [p, pca.explained_variance_ratio_.sum()]\n        \n        # Test Naive Bayes\n        sc, etrn, etst = run(xtrain, y_train, xtest, y_test, GaussianNB())\n        nb[i, :] = [p, sc, etrn, etst]\n        \n        # Test Random Forest\n        sc, etrn, etst = run(xtrain, y_train, xtest, y_test, RandomForestClassifier(n_estimators=50))\n        rf[i, :] = [p, sc, etrn, etst]\n        \n        # Test Linear SVM\n        sc, etrn, etst = run(xtrain, y_train, xtest, y_test, LinearSVC(C=1.0, max_iter=2000))\n        sv[i, :] = [p, sc, etrn, etst]\n        \n        print(f\"Done. (Variance explained: {tv[i, 1]:.3f})\")\n\n    # Save results to local files instead of external directory\n    print(\"\\nSaving results...\")\n    np.save(\"mnist_pca_tv.npy\", tv)  # Total variance explained\n    np.save(\"mnist_pca_nb.npy\", nb)  # Naive Bayes results\n    np.save(\"mnist_pca_rf.npy\", rf)  # Random Forest results\n    np.save(\"mnist_pca_sv.npy\", sv)  # Linear SVM results\n    \n    print(\"Results saved to:\")\n    print(\"  - mnist_pca_tv.npy: [n_components, explained_variance_ratio]\")\n    print(\"  - mnist_pca_nb.npy: [n_components, score, train_time, test_time] for Naive Bayes\")\n    print(\"  - mnist_pca_rf.npy: [n_components, score, train_time, test_time] for Random Forest\")\n    print(\"  - mnist_pca_sv.npy: [n_components, score, train_time, test_time] for Linear SVM\")\n    \n    # Print some summary statistics\n    print(\"\\nSummary - Best performance by number of components:\")\n    print(\"Naive Bayes:\")\n    best_nb_idx = np.argmax(nb[:, 1])\n    print(f\"  Best: {nb[best_nb_idx, 0]:.0f} components, score: {nb[best_nb_idx, 1]:.4f}\")\n    \n    print(\"Random Forest:\")\n    best_rf_idx = np.argmax(rf[:, 1])\n    print(f\"  Best: {rf[best_rf_idx, 0]:.0f} components, score: {rf[best_rf_idx, 1]:.4f}\")\n    \n    print(\"Linear SVM:\")\n    best_sv_idx = np.argmax(sv[:, 1])\n    print(f\"  Best: {sv[best_sv_idx, 0]:.0f} components, score: {sv[best_sv_idx, 1]:.4f}\")\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
   "cell_type": "markdown",
   "id": "e5eb0b1c",
   "metadata": {},
   "source": "## Classical Model Summary\n\nThe chapter concludes with a summary of pros and cons for the six classical models discussed:\n\n### Nearest Centroid\n\n- **Pros:** Simple implementation, fast training, low memory use, supports multiclass classification, fast inference.\n- **Cons:** Assumes each class forms a tight cluster in feature space, often too simplistic for complex data. Variants with multiple centroids per class can improve performance.\n\n### k-Nearest Neighbors (k-NN)\n\n- **Pros:** No explicit training required, works well with large datasets, supports multiclass classification naturally.\n- **Cons:** Slow inference because distances must be computed for every training sample, even with optimized algorithms.\n\n### Naive Bayes\n\n- **Pros:** Fast to train and classify, supports multiclass problems, works for both discrete and continuous features.\n- **Cons:** Assumes feature independence, which is rarely true in practice. Continuous features often require additional distributional assumptions (e.g., Gaussian).\n\n### Decision Trees\n\n- **Pros:** Fast training and inference, interpretable, supports multiclass and mixed feature types, can justify decisions with a clear path from root to leaf.\n- **Cons:** Prone to overfitting, interpretability decreases with tree size, requires balancing tree depth against accuracy.\n\n### Random Forests\n\n- **Pros:** Robust to overfitting, supports multiclass problems, reasonably fast to train and infer, less sensitive to feature scaling, accuracy improves with more trees.\n- **Cons:** Harder to interpret than single decision trees, inference time scales linearly with the number of trees, stochastic performance can vary slightly between trainings.\n\n### Support Vector Machines (SVMs)\n\n- **Pros:** Can achieve excellent performance, fast inference after training.\n- **Cons:** Multiclass requires multiple models, only supports continuous features, sensitive to feature scaling, difficult to train on large datasets with non-linear kernels, requires careful hyperparameter tuning.\n\n## When to Use Classical Models\n\nClassical models remain appropriate under certain conditions:\n\n1. **Small datasets:** They perform well when there are only tens or hundreds of examples, unlike deep learning models that require larger datasets.\n2. **Limited computational resources:** Simple models (nearest centroid, naive Bayes, decision trees, SVMs) are feasible on low-power devices; k-NN may be too slow unless the dataset is small.\n3. **Explainability:** Models like decision trees, k-NN, nearest centroid, and naive Bayes can explain their predictions, unlike deep neural networks.\n4. **Vector inputs without structure:** When features are independent and unstructured (not spatially correlated as in images), classical models are suitable.\n\nThese are rules of thumb, not hard rules. Deep learning could be used even when these conditions apply, but classic models may provide sufficient performance with less complexity.\n\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "de21f07c",
   "metadata": {},
   "source": ""
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
